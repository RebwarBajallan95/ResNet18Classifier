{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "code.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMKyNz9v01QV"
      },
      "source": [
        "## Load Tiny ImageNet Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pM8gfBWV0sUx"
      },
      "source": [
        "# This loads your google drive\n",
        "from google.colab import drive\n",
        "drive.mount( '/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6P23KWTQw6SD"
      },
      "source": [
        "!wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "!unzip -q tiny-imagenet-200.zip && ls tiny-imagenet-200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szki4aRs7Nc8"
      },
      "source": [
        "## Format validation data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mxWcpWYWTaOK"
      },
      "source": [
        "import os\n",
        "\n",
        "def create_val_img_folder(path_to_val):\n",
        "    '''\n",
        "    This method is responsible for separating validation images into separate sub folders\n",
        "    '''\n",
        "    dataset_dir = os.path.join(path_to_val)\n",
        "    val_dir = os.path.join(dataset_dir, 'val')\n",
        "    img_dir = os.path.join(val_dir, 'images')\n",
        "\n",
        "    fp = open(os.path.join(val_dir, 'val_annotations.txt'), 'r')\n",
        "    data = fp.readlines()\n",
        "    val_img_dict = {}\n",
        "    for line in data:\n",
        "        words = line.split('\\t')\n",
        "        val_img_dict[words[0]] = words[1]\n",
        "    fp.close()\n",
        "\n",
        "    # Create folder if not present and move images into proper folders\n",
        "    val_image_dir = \"IMagenet/tiny-imagenet-200/val_new\"\n",
        "    for img, folder in val_img_dict.items():\n",
        "        newpath = (os.path.join(val_image_dir, folder))\n",
        "        newpath += '/images/'\n",
        "        if not os.path.exists(newpath):\n",
        "            os.makedirs(newpath)\n",
        "        if os.path.exists(os.path.join(img_dir, img)):\n",
        "            os.rename(os.path.join(img_dir, img), os.path.join(newpath, img))\n",
        "\n",
        "create_val_img_folder('IMagenet/tiny-imagenet-200/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxzxFgTseSrr"
      },
      "source": [
        "! cd IMagenet/tiny-imagenet-200/val_new/n01443537/images && ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "28M4gmNZTk8H"
      },
      "source": [
        "## Get name for each label\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8oQjxIfX7j1T"
      },
      "source": [
        "def Get_label_name(path):\n",
        "  fp = open(os.path.join(path,'words.txt'), 'r')\n",
        "  data = fp.readlines()\n",
        "  \n",
        "  dict_labelsAll = {}\n",
        "  for line in data:\n",
        "   list = line.split()\n",
        "   label_name = list[1:]\n",
        "   s = \" \"\n",
        "   dict_labelsAll[list[0]] = s.join(label_name)\n",
        "  fp.close()\n",
        "\n",
        "  return dict_labelsAll\n",
        "\n",
        "dict_all_labels = Get_label_name('IMagenet/tiny-imagenet-200/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiAL4q7hDL61"
      },
      "source": [
        "import os\n",
        "def Get_200label_name(path, dict_labelsAll):\n",
        "  fp = open(os.path.join(path, 'val_annotations.txt'), 'r')\n",
        "  data = data = fp.readlines()\n",
        "  label_list = []\n",
        "\n",
        "  for line in data:\n",
        "    list = line.split()\n",
        "    label_list.append(list[1])\n",
        "  fp.close()\n",
        "  label_list = set(label_list)\n",
        "  label_list = sorted(label_list)\n",
        "  print(label_list)\n",
        "\n",
        "  dict_labels200 = {}\n",
        "  for i in range(len(label_list)):\n",
        "    dict_labels200[i] = dict_labelsAll[label_list[i]]\n",
        "\n",
        "  return dict_labels200, label_list\n",
        "\n",
        "dict_200_labels, labels_200 = Get_200label_name('IMagenet/tiny-imagenet-200/val', dict_all_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NqkczzGA_ScS"
      },
      "source": [
        "## Prepare test data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fPAG8RI2_V-5"
      },
      "source": [
        "import os\n",
        "\n",
        "def create_test_folder(path, labels_200):\n",
        "\n",
        "  train_dir = os.path.join(path, 'train')\n",
        "  test_image_dir = \"IMagenet/tiny-imagenet-200/test_images/\"\n",
        "  test_img_size = 50\n",
        "\n",
        "  for label in labels_200:\n",
        "    label_directory = os.path.join(train_dir, label)\n",
        "    label_directory += '/images/'\n",
        "\n",
        "    test_label = os.path.join(test_image_dir, label)\n",
        "    test_label += '/images/'\n",
        "    i = 0\n",
        "    for file in os.listdir(label_directory):\n",
        "      if not os.path.exists(test_label):\n",
        "        os.makedirs(test_label)\n",
        "\n",
        "      if i<test_img_size and os.path.exists(os.path.join(label_directory, file)):\n",
        "        if file not in 'boxes':\n",
        "          os.rename(os.path.join(label_directory, file), os.path.join(test_label, file))\n",
        "      else:\n",
        "        break\n",
        "      i = i+1\n",
        "\n",
        "create_test_folder('IMagenet/tiny-imagenet-200/', labels_200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jRM_s9qAuRNb"
      },
      "source": [
        "! cd IMagenet/tiny-imagenet-200/test_images/n01768244/images && ls | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VIJ_nkweUJNu"
      },
      "source": [
        "! cd IMagenet/tiny-imagenet-200/train/n01768244/images && ls | wc -l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43iX6MJb2E-t"
      },
      "source": [
        "## We run Pytorch on GPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AYN-O87s2ISJ"
      },
      "source": [
        "import torch\n",
        "# set seed\n",
        "torch.manual_seed(0)\n",
        "# set torch.device\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# Print to see if you have GPU available, if no GPU => change colab runtime\n",
        "print(f'GPU: {torch.cuda.get_device_name(0)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ZUp1qEi092Y"
      },
      "source": [
        "## Define Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjy0W-0809nQ"
      },
      "source": [
        "import math\n",
        "from tqdm.autonotebook import tqdm\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "path = \"IMagenet/tiny-imagenet-200/\"\n",
        "\n",
        "class Data():\n",
        "    \"\"\"\n",
        "        class for loading data\n",
        "    \"\"\"\n",
        "\n",
        "    \n",
        "    def __init__(self):\n",
        "\n",
        "        # TODO: ADD MORE IMAGE TRANSFORMATIONS?\n",
        "        self.transform = transforms.Compose([\n",
        "                              transforms.ToTensor(),\n",
        "                              #transforms.RandomRotation(20),\n",
        "                              #transforms.RandomHorizontalFlip(0.5),\n",
        "                              transforms.Normalize(mean=[0.4802, 0.4481, 0.3975], std=[0.2302, 0.2265, 0.2262]),\n",
        "                          ])\n",
        "        # Init data loaders\n",
        "        self.train_loader = self.load_data(path + 'train', batchsize=100, shuffle=True)\n",
        "        self.val_loader = self.load_data(path + 'val_new', batchsize=100, shuffle=False)\n",
        "        self.test_loader = self.load_data(path + 'test_images', batchsize=100, shuffle=False)\n",
        "\n",
        "\n",
        "    def load_data(self, ImagefolderPath:str, batchsize:int, shuffle=True) -> torch.utils.data.DataLoader:\n",
        "        \"\"\"\n",
        "            load images into Pytorch DataLoader given Image path. \n",
        "            OBS: Requires specific folder format\n",
        "        \"\"\"\n",
        "        imagenet_data = torchvision.datasets.ImageFolder(ImagefolderPath, transform=self.transform)\n",
        "        data_loader = torch.utils.data.DataLoader(imagenet_data,\n",
        "                                            batch_size=batchsize,\n",
        "                                            shuffle=shuffle,\n",
        "                                            pin_memory=True)\n",
        "        return data_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVkbwPRs1EJu"
      },
      "source": [
        "class Block(nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, output_dim, stride=1, downsampling=False):\n",
        "        super().__init__()\n",
        "        if isDropout:\n",
        "          self.dorpout1 = nn.Dropout2d(p=0.5, inplace=True)\n",
        "        self.conv1 = nn.Conv2d(input_dim, output_dim, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(output_dim)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        if isDropout:\n",
        "          self.dorpout2 = nn.Dropout2d(p=0.5, inplace=True)\n",
        "        self.conv2 = nn.Conv2d(output_dim, output_dim, kernel_size=3, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(output_dim)\n",
        "        \n",
        "        self.downsampling = downsampling\n",
        "    \n",
        "        if downsampling:\n",
        "            layers = []\n",
        "            layers.append(nn.Conv2d(input_dim, output_dim, kernel_size=1, stride=2, bias=False)) \n",
        "            layers.append(nn.BatchNorm2d(output_dim)) \n",
        "            self.downsample = nn.Sequential(*layers)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        \n",
        "        identity = x\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        if isDropout:\n",
        "          x = self.dorpout1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        if self.downsampling:\n",
        "            identity = self.downsample(identity)\n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        if isDropout:\n",
        "          x = self.dorpout2(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAwJO9eojlyS"
      },
      "source": [
        "class Resnet(nn.Module):\n",
        "    \"\"\"\n",
        "        18-layer ResNet architecture\n",
        "    \"\"\"\n",
        "\n",
        "    # TODO: HOW ABOUT PADDINGS?\n",
        "    def __init__(self, out_classes=200):\n",
        "        super().__init__()\n",
        "\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpooling = nn.MaxPool2d(3, stride=2)\n",
        "  \n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "\n",
        "        # APPEND ALL 3x3 CONV LAYERS - DIMENSION 64\n",
        "        conv_layers = []\n",
        "        conv_layers.append(Block(input_dim=64, output_dim=64, stride=1)) \n",
        "        conv_layers.append(Block(input_dim=64, output_dim=64, stride=1)) \n",
        "        self.conv2 = nn.Sequential(*conv_layers)\n",
        "\n",
        "        # APPEND ALL 3x3 CONV LAYERS - DIMENSION 128\n",
        "        conv_layers = []\n",
        "        conv_layers.append(Block(input_dim=64, output_dim=128, stride=2, downsampling=True)) \n",
        "        conv_layers.append(Block(input_dim=128, output_dim=128, stride=1)) \n",
        "        self.conv3 = nn.Sequential(*conv_layers)\n",
        "\n",
        "        # APPEND ALL 3x3 CONV LAYERS - DIMENSION 256\n",
        "        conv_layers = []\n",
        "        conv_layers.append(Block(input_dim=128, output_dim=256, stride=2, downsampling=True)) \n",
        "        conv_layers.append(Block(input_dim=256, output_dim=256, stride=1)) \n",
        "        self.conv4 = nn.Sequential(*conv_layers)\n",
        "\n",
        "         # APPEND ALL 3x3 CONV LAYERS - DIMENSION 256\n",
        "        conv_layers = []\n",
        "        conv_layers.append(Block(input_dim=256, output_dim=512, stride=2, downsampling=True)) \n",
        "        conv_layers.append(Block(input_dim=512, output_dim=512, stride=1)) \n",
        "        self.conv5 = nn.Sequential(*conv_layers)\n",
        "\n",
        "        # average pooling => selects the average of the \n",
        "        # activations in the feature map\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(output_size=(1,1))\n",
        "        # fully connected layers => classification layers\n",
        "        self.fc1 = nn.Linear(512, out_classes, bias=True)\n",
        "        \n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \"\"\"\n",
        "            Forward step\n",
        "        \"\"\"\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.maxpooling(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = self.conv5(x)\n",
        "        x = self.avg_pool(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "\n",
        "    def fit(self, epochs=10, verbose=True, validation=True):\n",
        "        \"\"\"\n",
        "            Function for training the network\n",
        "        \"\"\"\n",
        "        # NOTE: this uses softmax per default => No need to use softmax in forward I believe\n",
        "        criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "        # same paramters as used in the paper\n",
        "        optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
        "\n",
        "        # SGD, dropout\n",
        "        #optimizer = optim.SGD(self.parameters(), lr=0.1, momentum=0.9)\n",
        "\n",
        "        #Optimazer Adadelta\n",
        "        #optimizer = optim.Adadelta(self.parameters(), lr=0.1, weight_decay=0.0001)\n",
        "\n",
        "        \n",
        "        # Dataloaders\n",
        "        train_loader = data.train_loader\n",
        "        val_loader = data.val_loader\n",
        "\n",
        "        \n",
        "        training_losses = []\n",
        "        training_accuracy = []\n",
        "        validation_losses = []\n",
        "        validation_accuracy = []\n",
        "\n",
        "        for epoch in range(epochs):  \n",
        "            # training mode\n",
        "            self.train()\n",
        "            # Training loss\n",
        "            training_loss = 0\n",
        "            # Accuracy variables\n",
        "            correct = 0\n",
        "            total = 0\n",
        "            for x, y in tqdm(train_loader, desc=\"Epoch {}\".format(epoch + 1)):                \n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # map to cuda if GPU available\n",
        "                x = x.to(device)\n",
        "                y = y.to(device)\n",
        "\n",
        "                # Forward propagation\n",
        "                isDropout = False\n",
        "                outputs = self(x)\n",
        "                loss = criterion(outputs, y)\n",
        "                # Backward propagation\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "\n",
        "                # Training loss\n",
        "                training_loss+= loss.item()\n",
        "\n",
        "                # Calculate training accuracy\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += y.size(0)\n",
        "                correct += (predicted == y).sum().item()\n",
        "                \n",
        "\n",
        "            # Training accuracy\n",
        "            train_acc =  100 * (correct / total)\n",
        "            # Training loss\n",
        "            training_loss /= len(train_loader)\n",
        "            \n",
        "            # Print validation scores\n",
        "            if validation:\n",
        "              \n",
        "              val_loss, val_acc = validation_scores(self, val_loader, criterion)  \n",
        "              print(f'Validation Loss: {val_loss}') \n",
        "              print(f'Validation Accuracy: {val_acc}') \n",
        "              validation_losses.append(val_loss)\n",
        "              validation_accuracy.append(val_acc)\n",
        "      \n",
        "            # Priint training loss\n",
        "            if verbose:\n",
        "                print(f'Training Loss: {training_loss}')\n",
        "                print(f'Training Accuracy: {train_acc}')\n",
        "\n",
        "            # Store training scores\n",
        "            training_losses.append(training_loss) \n",
        "            training_accuracy.append(train_acc)\n",
        "\n",
        "\n",
        "        return training_losses, training_accuracy, validation_accuracy, validation_losses, epochs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMsiUaX-WfQ4"
      },
      "source": [
        "def validation_scores(net, val_loader, loss_function):\n",
        "  \"\"\"\n",
        "      Calculates validation loss and accuracy\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  loss = 0\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      net.eval()\n",
        "      for x, y in val_loader:  \n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          # Forward propagation\n",
        "          isDropout = False\n",
        "          outputs = net(x)\n",
        "          val_loss = loss_function(outputs, y)\n",
        "                    \n",
        "          loss+= val_loss.item()\n",
        "          # Calculate accuracy\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += y.size(0)\n",
        "          correct += (predicted == y).sum().item()\n",
        "          \n",
        "      \n",
        "  # Validation Accuracy\n",
        "  acc =  100 * (correct / total)\n",
        "  return loss/len(val_loader), acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTarrNg106lu"
      },
      "source": [
        "def test_acc(net, test_loader):#, scheduler):\n",
        "  \"\"\"\n",
        "      Calculates validation loss and accuracy\n",
        "  \"\"\"\n",
        "  correct = 0\n",
        "  total = 0\n",
        "\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "      for x, y in test_loader:  \n",
        "          x = x.to(device)\n",
        "          y = y.to(device)\n",
        "          # Forward propagation\n",
        "          isDropout = False\n",
        "          outputs = net(x)\n",
        "\n",
        "          # Calculate accuracy\n",
        "          _, predicted = torch.max(outputs.data, 1)\n",
        "          total += y.size(0)\n",
        "          correct += (predicted == y).sum().item()\n",
        "          \n",
        "      \n",
        "  # Validation Accuracy\n",
        "  acc =  100 * (correct / total)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhB32HWc1YCO"
      },
      "source": [
        "## Train and store model (To Drive)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z1GrF9Hj1OqO"
      },
      "source": [
        "isDropout = False\n",
        "resnet = Resnet()\n",
        "data = Data()\n",
        "resnet.to(device)\n",
        "training_losses, training_accuracy, validation_accuracy, validation_losses, epochs = resnet.fit(epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpvdYavnoiTh"
      },
      "source": [
        "## Visualization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqbQTMEXog-4"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_losses(training_loss: list, validation_loss: list, epochs: list) -> None:\n",
        "  \"\"\"\n",
        "      Plot the validation/training loss\n",
        "  \"\"\"\n",
        "  # PLOT RESULTS\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.ticklabel_format(useOffset=False, style='plain')\n",
        "  plt.plot(epochs, training_loss, label='Training loss')\n",
        "  plt.plot(epochs, validation_loss, label='Validation loss')\n",
        "  plt.title('Training/Validation loss without dropout')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Loss')\n",
        "  plt.legend()\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "plot_losses(training_losses, validation_losses, range(epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aqxCpg-vtYfD"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_accuracy(training_accuracy: list, validation_accuracy: list, epochs: list) -> None:\n",
        "  \"\"\"\n",
        "      Plot the validation/training loss\n",
        "  \"\"\"\n",
        "  # PLOT RESULTS\n",
        "  fig, ax = plt.subplots()\n",
        "  ax.ticklabel_format(useOffset=False, style='plain')\n",
        "  plt.plot(epochs, training_accuracy, label='Training Accuracy')\n",
        "  plt.plot(epochs, validation_accuracy, label='Validation Accuracy')\n",
        "  plt.title('Training/Validation Accuracy without dropout')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.ylabel('Accuracy')\n",
        "  plt.legend()\n",
        "  #plt.savefig(f'./smooth_loss_3_epochs')\n",
        "  plt.show()\n",
        "  plt.clf()\n",
        "\n",
        "\n",
        "plot_accuracy(training_accuracy, validation_accuracy, range(epochs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "we8JlFAr99cg"
      },
      "source": [
        "## Calculate the mean and std for the model runs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZsfjKDg1gca"
      },
      "source": [
        "import numpy as np\n",
        "print(np.mean([31.785, 34, 31.76]))\n",
        "print(np.std([31.785, 34, 31.76]))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}